{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40162d4e",
   "metadata": {
    "papermill": {
     "duration": 0.02089,
     "end_time": "2025-01-31T16:09:50.154606",
     "exception": false,
     "start_time": "2025-01-31T16:09:50.133716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Implementation of the Transformer architecture <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be005f0c",
   "metadata": {
    "papermill": {
     "duration": 0.019012,
     "end_time": "2025-01-31T16:09:50.193053",
     "exception": false,
     "start_time": "2025-01-31T16:09:50.174041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we propose a TensorFlow implementation from scratch of the Transformer as described in the original article [Vaswani et. al. Attention is all you need. Advances in Neural Information Processing Systems, 2017]. \n",
    "\n",
    "We give a detailed report on this article and define all the notations in an attached notebook. See https://www.kaggle.com/samuelnordmann/transformers-report-on-attention-is-all-you-need/\n",
    "\n",
    "The details of the implementation follow the same lines as the one of Andrew Ng in his Specialization course on Deep Learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d68cb0",
   "metadata": {
    "papermill": {
     "duration": 0.018928,
     "end_time": "2025-01-31T16:09:50.231058",
     "exception": false,
     "start_time": "2025-01-31T16:09:50.212130",
     "status": "completed"
    },
    "tags": [],
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Packages</a></span></li><li><span><a href=\"#Sub-layers\" data-toc-modified-id=\"Sub-layers-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Sub layers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Masking\" data-toc-modified-id=\"Masking-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Masking</a></span><ul class=\"toc-item\"><li><span><a href=\"#Padding-mask\" data-toc-modified-id=\"Padding-mask-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Padding mask</a></span></li><li><span><a href=\"#Look-ahead-Mask\" data-toc-modified-id=\"Look-ahead-Mask-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Look-ahead Mask</a></span></li></ul></li><li><span><a href=\"#Attention\" data-toc-modified-id=\"Attention-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Attention</a></span><ul class=\"toc-item\"><li><span><a href=\"#Single-head-attention\" data-toc-modified-id=\"Single-head-attention-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Single head attention</a></span></li><li><span><a href=\"#MultiHead-Attention\" data-toc-modified-id=\"MultiHead-Attention-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>MultiHead Attention</a></span></li></ul></li><li><span><a href=\"#Pointwise-FNN\" data-toc-modified-id=\"Pointwise-FNN-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Pointwise FNN</a></span></li><li><span><a href=\"#Positional-encoding\" data-toc-modified-id=\"Positional-encoding-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Positional encoding</a></span></li></ul></li><li><span><a href=\"#Encoder\" data-toc-modified-id=\"Encoder-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Encoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#Encoder-layer\" data-toc-modified-id=\"Encoder-layer-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Encoder layer</a></span></li><li><span><a href=\"#Full-Encoder\" data-toc-modified-id=\"Full-Encoder-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Full Encoder</a></span></li></ul></li><li><span><a href=\"#Decoder\" data-toc-modified-id=\"Decoder-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Decoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decoder-layer\" data-toc-modified-id=\"Decoder-layer-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Decoder layer</a></span></li><li><span><a href=\"#Full-decoder\" data-toc-modified-id=\"Full-decoder-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Full decoder</a></span></li></ul></li><li><span><a href=\"#Transformer\" data-toc-modified-id=\"Transformer-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Transformer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Compilation-of-the-model\" data-toc-modified-id=\"Compilation-of-the-model-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Compilation of the model</a></span></li></ul></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Learning-rate-scheduler\" data-toc-modified-id=\"Learning-rate-scheduler-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Learning rate scheduler</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3a15c",
   "metadata": {
    "papermill": {
     "duration": 0.018869,
     "end_time": "2025-01-31T16:09:50.268927",
     "exception": false,
     "start_time": "2025-01-31T16:09:50.250058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38c4eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:09:50.316913Z",
     "iopub.status.busy": "2025-01-31T16:09:50.316399Z",
     "iopub.status.idle": "2025-01-31T16:09:56.402764Z",
     "shell.execute_reply": "2025-01-31T16:09:56.402212Z"
    },
    "papermill": {
     "duration": 6.11344,
     "end_time": "2025-01-31T16:09:56.402908",
     "exception": false,
     "start_time": "2025-01-31T16:09:50.289468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, Input, Dropout, LayerNormalization, Conv1D, Reshape\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908473da",
   "metadata": {
    "papermill": {
     "duration": 0.019495,
     "end_time": "2025-01-31T16:09:56.442844",
     "exception": false,
     "start_time": "2025-01-31T16:09:56.423349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sub layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a6b28",
   "metadata": {
    "papermill": {
     "duration": 0.019475,
     "end_time": "2025-01-31T16:09:56.481850",
     "exception": false,
     "start_time": "2025-01-31T16:09:56.462375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0da5e",
   "metadata": {
    "papermill": {
     "duration": 0.020332,
     "end_time": "2025-01-31T16:09:56.521819",
     "exception": false,
     "start_time": "2025-01-31T16:09:56.501487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Single head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4aa8fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:09:56.566610Z",
     "iopub.status.busy": "2025-01-31T16:09:56.566041Z",
     "iopub.status.idle": "2025-01-31T16:09:56.568543Z",
     "shell.execute_reply": "2025-01-31T16:09:56.568941Z"
    },
    "papermill": {
     "duration": 0.027589,
     "end_time": "2025-01-31T16:09:56.569055",
     "exception": false,
     "start_time": "2025-01-31T16:09:56.541466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "\n",
    "    Arguments:\n",
    "        Q -- query shape == (..., Tq, dk)\n",
    "        K -- key shape == (..., Tv, dk)\n",
    "        V -- value shape == (..., Tv, dv)\n",
    "        mask: Float tensor with shape broadcastable to (..., Tq, Tv). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        output -- (attention,attention_weights)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Compute the scaled dot-product Qâ€¢K\n",
    "    matmul_QK = tf.matmul(Q,K,transpose_b=True)  # dot-product of shape (..., Tq, Tv)\n",
    "\n",
    "    dk = K.shape[-1]\n",
    "    scaled_attention_logits = matmul_QK/np.sqrt(dk) # scaled dot-product of shape (..., Tq, Tv)\n",
    "\n",
    "    # Add the mask to the scaled dot-product\n",
    "    if mask is not None: \n",
    "        scaled_attention_logits += (1. - mask) *(-1e9)\n",
    "\n",
    "    # Compute the Softmax\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # weights of shape (..., Tq, Tv)\n",
    "\n",
    "    #Multiply with V\n",
    "    output = tf.matmul(attention_weights,V)  # Attention representation of shape (..., Tq, dv)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f527f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:00.283043Z",
     "iopub.status.busy": "2025-01-31T16:09:59.946173Z",
     "iopub.status.idle": "2025-01-31T16:10:01.678128Z",
     "shell.execute_reply": "2025-01-31T16:10:01.677483Z"
    },
    "papermill": {
     "duration": 5.089618,
     "end_time": "2025-01-31T16:10:01.678284",
     "exception": false,
     "start_time": "2025-01-31T16:09:56.588666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 9, 128)\n"
     ]
    }
   ],
   "source": [
    "## DEBUG\n",
    "\n",
    "batch_size,Tq, Tv, dk, dv= 16,9,9,64,128 # we need Tq=Tv\n",
    "Q= tf.random.uniform((batch_size,Tq, dk))\n",
    "K= tf.random.uniform((batch_size,Tv, dk))\n",
    "V= tf.random.uniform((batch_size,Tv, dv))\n",
    "\n",
    "A,_=scaled_dot_product_attention(Q, K, V)\n",
    "print(A.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea73d1a",
   "metadata": {
    "papermill": {
     "duration": 0.020159,
     "end_time": "2025-01-31T16:10:01.719007",
     "exception": false,
     "start_time": "2025-01-31T16:10:01.698848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### MultiHead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ac23f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:01.768453Z",
     "iopub.status.busy": "2025-01-31T16:10:01.767897Z",
     "iopub.status.idle": "2025-01-31T16:10:01.770030Z",
     "shell.execute_reply": "2025-01-31T16:10:01.770437Z"
    },
    "papermill": {
     "duration": 0.031774,
     "end_time": "2025-01-31T16:10:01.770571",
     "exception": false,
     "start_time": "2025-01-31T16:10:01.738797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Multihead_Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, H, d_model, dk, dv):\n",
    "        \n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        H -- number of heads (=8 in the paper)\n",
    "        d_models -- embedding dimension (=512 in the paper)\n",
    "        dk -- depth of Q and K (=64 in the paper)\n",
    "        dv -- depth of V (=64 in the paper)\n",
    "        \"\"\"\n",
    "    \n",
    "        super(Multihead_Attention, self).__init__()\n",
    "        \n",
    "        initializer = tf.keras.initializers.GlorotUniform()\n",
    "        self.WQ = tf.Variable(initializer(shape=(H, d_model, dk)), trainable=True)\n",
    "        self.WK = tf.Variable(initializer(shape=(H, d_model, dk)), trainable=True)\n",
    "        self.WV = tf.Variable(initializer(shape=(H, d_model, dv)), trainable=True)\n",
    "        self.WO = tf.Variable(initializer(shape=(H*dv,d_model)), trainable=True)\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask=None):\n",
    "        \"\"\"\n",
    "        Calculate the attention weights.\n",
    "\n",
    "        Arguments:\n",
    "            Q -- query shape == (..., Tq, d_model)\n",
    "            K -- key shape == (..., Tv, d_model)\n",
    "            V -- value shape == (..., Tv, d_model)\n",
    "            mask: Float tensor with shape broadcastable to (..., Tq, Tv). Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            output -- Multihead attention A of shape (batch_size, Tq, d_model)\n",
    "        \"\"\"\n",
    "        #Projecting Q,K,V to Qh, Kh, Vh. The H projection are stacked on the penultiem axis\n",
    "        Qh= tf.experimental.numpy.dot(Q, self.WQ) #of shape (batch_size, Tq, H, dk)\n",
    "        Kh= tf.experimental.numpy.dot(K, self.WK) #of shape (batch_size, Tv, H, dk)\n",
    "        Vh= tf.experimental.numpy.dot(V, self.WV) #of shape (batch_size, Tv, H, dv)\n",
    "        \n",
    "        #Transposition\n",
    "        Qh=tf.transpose(Qh, [0,2,1,3]) #of shape (batch_size, H, Tq, dk)\n",
    "        Kh=tf.transpose(Kh, [0,2,1,3]) #of shape (batch_size, H, Tv, dk)\n",
    "        Vh=tf.transpose(Vh, [0,2,1,3]) #of shape (batch_size, H, Tv, dv)\n",
    "        \n",
    "        # Computing the dot-product attention\n",
    "        Ah,_=scaled_dot_product_attention(Qh, Kh, Vh, mask=mask) #of shape (batch_size, H, Tq, dv)\n",
    "        \n",
    "        #Flattening the H and dv axis and projecting back to d_model\n",
    "#        A = tf.reshape(Ah,(*Ah.shape[:-2],-1))\n",
    "        s=Ah.shape\n",
    "        A = tf.reshape(Ah,(s[0],s[2],s[1]*s[3])) #of shape (batch_size, Tq, H*dv)\n",
    "        A= tf.experimental.numpy.dot(A, self.WO) #of shape (batch_size, Tq, d_model)\n",
    "        \n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e81a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:01.814926Z",
     "iopub.status.busy": "2025-01-31T16:10:01.814461Z",
     "iopub.status.idle": "2025-01-31T16:10:01.886403Z",
     "shell.execute_reply": "2025-01-31T16:10:01.886741Z"
    },
    "papermill": {
     "duration": 0.096468,
     "end_time": "2025-01-31T16:10:01.886878",
     "exception": false,
     "start_time": "2025-01-31T16:10:01.790410",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 9, 512)\n"
     ]
    }
   ],
   "source": [
    "## DEBUG\n",
    "\n",
    "H, d_model, dk, dv=8,512,64,32\n",
    "batch_size, Tq, Tv = 16,9,9\n",
    "\n",
    "mha_layer= Multihead_Attention(H, d_model, dk, dv)\n",
    "\n",
    "Q= tf.random.uniform((batch_size, Tq, d_model))\n",
    "K= tf.random.uniform((batch_size, Tv, d_model))\n",
    "V= tf.random.uniform((batch_size, Tv, d_model))\n",
    "\n",
    "A=mha_layer(Q,K,V)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d6b07",
   "metadata": {
    "papermill": {
     "duration": 0.020115,
     "end_time": "2025-01-31T16:10:01.928528",
     "exception": false,
     "start_time": "2025-01-31T16:10:01.908413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pointwise FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac2ebe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:01.974288Z",
     "iopub.status.busy": "2025-01-31T16:10:01.973746Z",
     "iopub.status.idle": "2025-01-31T16:10:01.976335Z",
     "shell.execute_reply": "2025-01-31T16:10:01.975836Z"
    },
    "papermill": {
     "duration": 0.027767,
     "end_time": "2025-01-31T16:10:01.976440",
     "exception": false,
     "start_time": "2025-01-31T16:10:01.948673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FNNLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff):\n",
    "        \n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        d_model -- the dimension of the embedding (=64 in the paper)\n",
    "        dff -- the dimension of the hidden layer of the FNN (=2048 in the paper)\n",
    "        \"\"\"\n",
    "            \n",
    "        super(FNNLayer, self).__init__()\n",
    "\n",
    "        self.layer1 = Conv1D(filters=dff, kernel_size=1,activation=\"relu\")\n",
    "        self.layer2 = Conv1D(filters=d_model, kernel_size=1)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "            \n",
    "        Returns:\n",
    "            fnn_layer_out -- Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        x=self.layer1(x)\n",
    "        fnn_layer_out=self.layer2(x)\n",
    "\n",
    "        \n",
    "        return fnn_layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dffd10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:02.030458Z",
     "iopub.status.busy": "2025-01-31T16:10:02.029054Z",
     "iopub.status.idle": "2025-01-31T16:10:02.055142Z",
     "shell.execute_reply": "2025-01-31T16:10:02.055571Z"
    },
    "papermill": {
     "duration": 0.057638,
     "end_time": "2025-01-31T16:10:02.055696",
     "exception": false,
     "start_time": "2025-01-31T16:10:01.998058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 9, 64)\n"
     ]
    }
   ],
   "source": [
    "## DEBUG\n",
    "\n",
    "d_model, dff = 64, 2048\n",
    "fnn_layer= FNNLayer(d_model, dff)\n",
    "\n",
    "batch_size, Tv= 16, 9\n",
    "x=tf.random.uniform((batch_size, Tv, d_model))\n",
    "\n",
    "print(fnn_layer(x).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540337fb",
   "metadata": {
    "papermill": {
     "duration": 0.020309,
     "end_time": "2025-01-31T16:10:02.096784",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.076475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b04080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:02.144472Z",
     "iopub.status.busy": "2025-01-31T16:10:02.143754Z",
     "iopub.status.idle": "2025-01-31T16:10:02.145739Z",
     "shell.execute_reply": "2025-01-31T16:10:02.146158Z"
    },
    "papermill": {
     "duration": 0.028686,
     "end_time": "2025-01-31T16:10:02.146313",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.117627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d):\n",
    "    \"\"\"\n",
    "    Precomputes a matrix with all the positional encodings \n",
    "    \n",
    "    Arguments:\n",
    "        positions (int) -- Maximum number of positions to be encoded \n",
    "        d (int) -- Encoding size d_model\n",
    "    \n",
    "        arguments de get_angles:\n",
    "            pos -- Column vector containing the positions [[0], [1], ...,[N-1]]\n",
    "            k --   Row vector containing the dimension span [[0, 1, 2, ..., d-1]]\n",
    "            d(integer) -- Encoding size\n",
    "            \n",
    "    Returns:\n",
    "        pos_encoding -- (1, position, d_model) A matrix with the positional encodings\n",
    "    \"\"\"\n",
    "    # initialize a matrix angle_rads of all the angles\n",
    "    pos=np.arange(positions)[:, np.newaxis] #Column vector containing the position span [0,1,..., positions]\n",
    "    k= np.arange(d)[np.newaxis, :]  #Row vector containing the dimension span [[0, 1, ..., d-1]]\n",
    "    i = k//2\n",
    "    angle_rads = pos/(10000**(2*i/d)) #Matrix of angles indexed by (pos,i)\n",
    "    \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    #adds batch axis\n",
    "    pos_encoding = angle_rads[np.newaxis, ...] \n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792d29d",
   "metadata": {
    "papermill": {
     "duration": 0.020861,
     "end_time": "2025-01-31T16:10:02.189305",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.168444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us plot the obtained results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9aa552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:02.236835Z",
     "iopub.status.busy": "2025-01-31T16:10:02.236341Z",
     "iopub.status.idle": "2025-01-31T16:10:02.520511Z",
     "shell.execute_reply": "2025-01-31T16:10:02.520890Z"
    },
    "papermill": {
     "duration": 0.31034,
     "end_time": "2025-01-31T16:10:02.521031",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.210691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "positions, d=50,512\n",
    "pos_encoding = positional_encoding(positions, d)\n",
    "\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('d')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4940678",
   "metadata": {
    "papermill": {
     "duration": 0.023719,
     "end_time": "2025-01-31T16:10:02.567519",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.543800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be2eec",
   "metadata": {
    "papermill": {
     "duration": 0.021895,
     "end_time": "2025-01-31T16:10:02.611780",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.589885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are two types of masks that are useful when building your Transformer network: the padding mask and the look-ahead mask. Both help the softmax computation give the appropriate weights to the words in the input sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f5b765",
   "metadata": {
    "papermill": {
     "duration": 0.022154,
     "end_time": "2025-01-31T16:10:02.656163",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.634009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Padding mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f914550",
   "metadata": {
    "papermill": {
     "duration": 0.022095,
     "end_time": "2025-01-31T16:10:02.701190",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.679095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When passing sequences into a transformer model, it is important that they are of uniform length. You can achieve this by padding the sequence with zeros, and truncating sentences that exceed the maximum length of your model.\n",
    "\n",
    "In the case where the sequence is padded with zeros, we need to create a mask to let the algorithm know that it should discard the zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba2bfbc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:02.750333Z",
     "iopub.status.busy": "2025-01-31T16:10:02.749803Z",
     "iopub.status.idle": "2025-01-31T16:10:02.752139Z",
     "shell.execute_reply": "2025-01-31T16:10:02.752566Z"
    },
    "papermill": {
     "duration": 0.029478,
     "end_time": "2025-01-31T16:10:02.752692",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.723214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(decoder_token_ids):\n",
    "    \"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "    \n",
    "    Arguments:\n",
    "        decoder_token_ids -- (n, m) matrix. n=batch_size, m=fixed size of input sentences\n",
    "    \n",
    "    Returns:\n",
    "        mask -- (n, 1, m) binary tensor\n",
    "    \"\"\"    \n",
    "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding to the attention logits.\n",
    "    return seq[:, tf.newaxis, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6421c4b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:02.801888Z",
     "iopub.status.busy": "2025-01-31T16:10:02.801381Z",
     "iopub.status.idle": "2025-01-31T16:10:02.809499Z",
     "shell.execute_reply": "2025-01-31T16:10:02.809079Z"
    },
    "papermill": {
     "duration": 0.034483,
     "end_time": "2025-01-31T16:10:02.809609",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.775126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 0. 0. 1.]]\n",
      "\n",
      " [[1. 1. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1. 1.]]], shape=(3, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[7., 6., 0., 0., 1.], [1., 2., 3., 0., 0.], [0., 0., 0., 4., 5.]])\n",
    "print(create_padding_mask(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9381d2",
   "metadata": {
    "papermill": {
     "duration": 0.022063,
     "end_time": "2025-01-31T16:10:02.853893",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.831830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Look-ahead Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592592e4",
   "metadata": {
    "papermill": {
     "duration": 0.022482,
     "end_time": "2025-01-31T16:10:02.898837",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.876355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In training, we have access to the complete correct output of the training example. The look-ahead mask helps the model pretend that it correctly predicted a part of the output and see if, without looking ahead, it can correctly predict the next output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231421d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:02.951145Z",
     "iopub.status.busy": "2025-01-31T16:10:02.950690Z",
     "iopub.status.idle": "2025-01-31T16:10:02.952797Z",
     "shell.execute_reply": "2025-01-31T16:10:02.953157Z"
    },
    "papermill": {
     "duration": 0.029951,
     "end_time": "2025-01-31T16:10:02.953314",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.923363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(sequence_length):\n",
    "    \"\"\"\n",
    "    Returns an upper triangular matrix filled with ones\n",
    "    \n",
    "    Arguments:\n",
    "        sequence_length -- matrix size\n",
    "    \n",
    "    Returns:\n",
    "        mask -- (size, size) tensor\n",
    "    \"\"\"\n",
    "    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "509b8094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:03.003565Z",
     "iopub.status.busy": "2025-01-31T16:10:03.002804Z",
     "iopub.status.idle": "2025-01-31T16:10:03.014547Z",
     "shell.execute_reply": "2025-01-31T16:10:03.013986Z"
    },
    "papermill": {
     "duration": 0.038788,
     "end_time": "2025-01-31T16:10:03.014653",
     "exception": false,
     "start_time": "2025-01-31T16:10:02.975865",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "create_look_ahead_mask(x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e72166",
   "metadata": {
    "papermill": {
     "duration": 0.02264,
     "end_time": "2025-01-31T16:10:03.061553",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.038913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc934b8",
   "metadata": {
    "papermill": {
     "duration": 0.02268,
     "end_time": "2025-01-31T16:10:03.106905",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.084225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoder layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0099139a",
   "metadata": {
    "papermill": {
     "duration": 0.022663,
     "end_time": "2025-01-31T16:10:03.152651",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.129988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We recall that the encoder layer is composed by a multi-head self-attention mechanism, followed by a positionwise fully connected feed-forward network. This archirecture includes a residual connection around each of the two sub-layers, followed by layer normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ebc5fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:03.206364Z",
     "iopub.status.busy": "2025-01-31T16:10:03.205842Z",
     "iopub.status.idle": "2025-01-31T16:10:03.208337Z",
     "shell.execute_reply": "2025-01-31T16:10:03.207836Z"
    },
    "papermill": {
     "duration": 0.033082,
     "end_time": "2025-01-31T16:10:03.208451",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.175369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, H, d_model, dk, dv, dff, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        \n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "\n",
    "        H -- number of heads (=8 in the paper)\n",
    "        d_models -- embedding dimension (=512 in the paper)\n",
    "        dk -- depth of Q and K (=64 in the paper)\n",
    "        dv -- depth of V (=64 in the paper)\n",
    "        dff -- the dimension of the hidden layer of the FNN (=2048 in the paper)\n",
    "        dropout_rate -- Dropout parameter used (during training) before all the residual connections\n",
    "        layernorm_eps -- eta regularizing parameter for the Normalization layer \n",
    "        \"\"\"\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = Multihead_Attention(H, d_model, dk, dv)\n",
    "        self.ffn = FNNLayer(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.dropout_mha = Dropout(dropout_rate)\n",
    "        self.dropout_ffn = Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, Tq, d_model)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers. Defaults to False\n",
    "            mask -- Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input. Defaults to None\n",
    "        Returns:\n",
    "            encoder_layer_out -- Tensor of shape (batch_size, Tq, d_model)\n",
    "        \"\"\"\n",
    "        A = self.mha(x,x,x,mask=mask) # Self attention (batch_size, Tq, d_model)\n",
    "        A = self.dropout_mha(A, training=training) #Apply Dropout during training\n",
    "        \n",
    "        \n",
    "        #  Residual connection + Layer normalization\n",
    "        out1 = self.layernorm1(x+A)  # (batch_size, Tq, d_model)\n",
    "\n",
    "        # Pointwise ffn\n",
    "        ffn_output = self.ffn(out1) # (batch_size, Tq, d_model)\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training) # Apply Dropout during training\n",
    "        \n",
    "        # Residual connection + Layer normalization\n",
    "        encoder_layer_out = self.layernorm2(ffn_output+out1)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        return encoder_layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c6a9c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:03.259399Z",
     "iopub.status.busy": "2025-01-31T16:10:03.258641Z",
     "iopub.status.idle": "2025-01-31T16:10:03.306135Z",
     "shell.execute_reply": "2025-01-31T16:10:03.305669Z"
    },
    "papermill": {
     "duration": 0.074966,
     "end_time": "2025-01-31T16:10:03.306264",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.231298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 27, 512)\n"
     ]
    }
   ],
   "source": [
    "## DEBUG\n",
    "\n",
    "H, d_model, dk, dv, dff = 8, 512, 64, 32, 2048\n",
    "layer = EncoderLayer(H, d_model, dk, dv, dff)\n",
    "\n",
    "batch_size, Tq= 43, 27\n",
    "x = tf.random.uniform((batch_size, Tq, d_model))\n",
    "\n",
    "output = layer(x,training=True)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84681c",
   "metadata": {
    "papermill": {
     "duration": 0.023022,
     "end_time": "2025-01-31T16:10:03.352828",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.329806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Full Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22265fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:03.406670Z",
     "iopub.status.busy": "2025-01-31T16:10:03.406140Z",
     "iopub.status.idle": "2025-01-31T16:10:03.408608Z",
     "shell.execute_reply": "2025-01-31T16:10:03.408137Z"
    },
    "papermill": {
     "duration": 0.032124,
     "end_time": "2025-01-31T16:10:03.408705",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.376581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, N, H, d_model, dk, dv, dff, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        \n",
    "        N -- number of stackeds Encoder layers (=6 in the paper)\n",
    "        H -- number of heads (=8 in the paper)\n",
    "        d_models -- embedding dimension (=512 in the paper)\n",
    "        dk -- depth of Q and K (=64 in the paper)\n",
    "        dv -- depth of V (=64 in the paper)\n",
    "        dff -- the dimension of the hidden layer of the FNN (=2048 in the paper)\n",
    "        dropout_rate -- Dropout parameter used (during training) before all the residual connections\n",
    "        layernorm_eps -- eta regularizing parameter for the Normalization layer \n",
    "        \"\"\"\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.layers=[EncoderLayer(H, d_model, dk, dv, dff, \n",
    "                                  dropout_rate=dropout_rate, \n",
    "                                  layernorm_eps=layernorm_eps)\n",
    "                                  for i in range(N)]\n",
    "    \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, Tq, d_model)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers. Defaults to False\n",
    "            mask -- Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input. Defaults to None\n",
    "        Returns:\n",
    "            encoder_out -- Tensor of shape (batch_size, Tq, d_model)\n",
    "        \"\"\"\n",
    "                                  \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, training=training, mask=mask)\n",
    "                                  \n",
    "        return x\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58a9a210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:03.461081Z",
     "iopub.status.busy": "2025-01-31T16:10:03.460636Z",
     "iopub.status.idle": "2025-01-31T16:10:03.587464Z",
     "shell.execute_reply": "2025-01-31T16:10:03.586915Z"
    },
    "papermill": {
     "duration": 0.15558,
     "end_time": "2025-01-31T16:10:03.587592",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.432012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 27, 512)\n"
     ]
    }
   ],
   "source": [
    "## DEBUG\n",
    "\n",
    "N,H, d_model, dk, dv, dff = 6,8, 512, 64, 32, 2048\n",
    "encoder = Encoder(N,H, d_model, dk, dv, dff)\n",
    "\n",
    "batch_size, Tq= 43, 27\n",
    "x = tf.random.uniform((batch_size, Tq, d_model))\n",
    "\n",
    "output = encoder(x,training=True)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31aa96",
   "metadata": {
    "papermill": {
     "duration": 0.023566,
     "end_time": "2025-01-31T16:10:03.635865",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.612299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c0c12",
   "metadata": {
    "papermill": {
     "duration": 0.023855,
     "end_time": "2025-01-31T16:10:03.683525",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.659670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27efb0c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:03.739508Z",
     "iopub.status.busy": "2025-01-31T16:10:03.732717Z",
     "iopub.status.idle": "2025-01-31T16:10:03.741879Z",
     "shell.execute_reply": "2025-01-31T16:10:03.741417Z"
    },
    "papermill": {
     "duration": 0.034839,
     "end_time": "2025-01-31T16:10:03.741972",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.707133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, H, d_model, dk, dv, dff, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        \n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "\n",
    "        H -- number of heads (=8 in the paper)\n",
    "        d_models -- embedding dimension (=512 in the paper)\n",
    "        dk -- depth of Q and K (=64 in the paper)\n",
    "        dv -- depth of V (=64 in the paper)\n",
    "        dff -- the dimension of the hidden layer of the FNN (=2048 in the paper)\n",
    "        dropout_rate -- Dropout parameter used (during training) before all the residual connections\n",
    "        layernorm_eps -- eta regularizing parameter for the Normalization layer \n",
    "        \"\"\"\n",
    "        \n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = Multihead_Attention(H, d_model, dk, dv)\n",
    "        self.mha2 = Multihead_Attention(H, d_model, dk, dv)\n",
    "        self.ffn = FNNLayer(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm3 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.dropout_mha1 = Dropout(dropout_rate)\n",
    "        self.dropout_mha2 = Dropout(dropout_rate)                                     \n",
    "        self.dropout_ffn = Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, encoder_output, training=False, look_ahead_mask=None, padding_mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the Decoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, Tv, d_model)\n",
    "            encoder_output --  Tensor of shape (batch_size, Tv, d_model)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers. Defaults to False\n",
    "            look_ahead_mask -- Boolean mask for the target_input. Defaults to None\n",
    "            padding_mask -- Boolean mask for the second multihead attention layer. Defaults to None\n",
    "        Returns:\n",
    "            decoder_layer_out -- Tensor of shape (batch_size, Tq, d_model)\n",
    "        \"\"\"\n",
    "        # 1st Masked MultiHead attention                                     \n",
    "        A1 = self.mha1(x,x,x,mask=look_ahead_mask) # Self attention (batch_size, Tq, d_model)\n",
    "        A1 = self.dropout_mha1(A1, training=training) #Apply Dropout during training\n",
    "        \n",
    "        #  Residual connection + Layer normalization\n",
    "        out1 = self.layernorm1(x+A1)  # (batch_size, Tq, d_model)\n",
    "\n",
    "        # 2nd Masked MultiHead attention                                     \n",
    "        A2 = self.mha2(x,encoder_output,encoder_output,mask=padding_mask) # Self attention (batch_size, Tq, d_model)\n",
    "        A2 = self.dropout_mha2(A2, training=training) #Apply Dropout during training\n",
    "        \n",
    "        \n",
    "        #  Residual connection + Layer normalization\n",
    "        out2 = self.layernorm2(out1+A2)  # (batch_size, Tq, d_model)\n",
    "                                             \n",
    "        # Pointwise ffn\n",
    "        ffn_output = self.ffn(out2) # (batch_size, Tq, d_model)\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training) # Apply Dropout during training\n",
    "        \n",
    "        # Residual connection + Layer normalization\n",
    "        decoder_layer_out = self.layernorm3(ffn_output+out2)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        return decoder_layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93284587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:03.795082Z",
     "iopub.status.busy": "2025-01-31T16:10:03.794357Z",
     "iopub.status.idle": "2025-01-31T16:10:03.830191Z",
     "shell.execute_reply": "2025-01-31T16:10:03.829786Z"
    },
    "papermill": {
     "duration": 0.064468,
     "end_time": "2025-01-31T16:10:03.830311",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.765843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## DEBUG\n",
    "\n",
    "H, d_model, dk, dv, dff = 8, 512, 64, 32, 2048\n",
    "layer = DecoderLayer(H, d_model, dk, dv, dff)\n",
    "\n",
    "batch_size, Tq, Tv= 43, 57, 57\n",
    "x = tf.random.uniform((batch_size, Tv, d_model))\n",
    "encoder_output = tf.random.uniform((batch_size, Tq, d_model))\n",
    "\n",
    "output = layer(x,encoder_output,training=True)\n",
    "#print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69841f56",
   "metadata": {
    "papermill": {
     "duration": 0.023962,
     "end_time": "2025-01-31T16:10:03.878296",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.854334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Full decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79b36aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:03.933608Z",
     "iopub.status.busy": "2025-01-31T16:10:03.933066Z",
     "iopub.status.idle": "2025-01-31T16:10:03.935278Z",
     "shell.execute_reply": "2025-01-31T16:10:03.935629Z"
    },
    "papermill": {
     "duration": 0.033343,
     "end_time": "2025-01-31T16:10:03.935745",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.902402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, N, H, d_model, dk, dv, dff, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        \n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "\n",
    "        N -- number of stackeds Decoder layers (=6 in the paper)\n",
    "        H -- number of heads (=8 in the paper)\n",
    "        d_models -- embedding dimension (=512 in the paper)\n",
    "        dk -- depth of Q and K (=64 in the paper)\n",
    "        dv -- depth of V (=64 in the paper)\n",
    "        dff -- the dimension of the hidden layer of the FNN (=2048 in the paper)\n",
    "        dropout_rate -- Dropout parameter used (during training) before all the residual connections\n",
    "        layernorm_eps -- eta regularizing parameter for the Normalization layer \n",
    "        \"\"\"\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.layers=[DecoderLayer(H, d_model, dk, dv, dff, \n",
    "                                  dropout_rate=dropout_rate, \n",
    "                                  layernorm_eps=layernorm_eps)\n",
    "                                  for i in range(N)]\n",
    "    \n",
    "    def call(self, x, encoder_output, training=False, look_ahead_mask=None, padding_mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the Decoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, Tv, d_model)\n",
    "            encoder_output --  Tensor of shape (batch_size, Tv, d_model)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers. Defaults to False\n",
    "            look_ahead_mask -- Boolean mask for the target_input. Defaults to None\n",
    "            padding_mask -- Boolean mask for the second multihead attention layer. Defaults to None\n",
    "        Returns:\n",
    "            decoder_out -- Tensor of shape (batch_size, Tq, d_model)\n",
    "        \"\"\"\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x,encoder_output, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "                                  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "520c4b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:03.989351Z",
     "iopub.status.busy": "2025-01-31T16:10:03.988878Z",
     "iopub.status.idle": "2025-01-31T16:10:04.179898Z",
     "shell.execute_reply": "2025-01-31T16:10:04.179516Z"
    },
    "papermill": {
     "duration": 0.220212,
     "end_time": "2025-01-31T16:10:04.179996",
     "exception": false,
     "start_time": "2025-01-31T16:10:03.959784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 57, 512)\n"
     ]
    }
   ],
   "source": [
    "## DEBUG\n",
    "\n",
    "N,H, d_model, dk, dv, dff = 6,8, 512, 64, 32, 2048\n",
    "decoder = Decoder(N,H, d_model, dk, dv, dff)\n",
    "\n",
    "batch_size, Tq, Tv= 43, 57, 57\n",
    "x = tf.random.uniform((batch_size, Tv, d_model))\n",
    "encoder_output = tf.random.uniform((batch_size, Tq, d_model))\n",
    "\n",
    "output = decoder(x,encoder_output,training=True)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af8ca4",
   "metadata": {
    "papermill": {
     "duration": 0.02412,
     "end_time": "2025-01-31T16:10:04.228191",
     "exception": false,
     "start_time": "2025-01-31T16:10:04.204071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b1f55",
   "metadata": {
    "papermill": {
     "duration": 0.023821,
     "end_time": "2025-01-31T16:10:04.276535",
     "exception": false,
     "start_time": "2025-01-31T16:10:04.252714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Complete architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61337d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:04.333394Z",
     "iopub.status.busy": "2025-01-31T16:10:04.326917Z",
     "iopub.status.idle": "2025-01-31T16:10:04.335411Z",
     "shell.execute_reply": "2025-01-31T16:10:04.335745Z"
    },
    "papermill": {
     "duration": 0.034976,
     "end_time": "2025-01-31T16:10:04.335861",
     "exception": false,
     "start_time": "2025-01-31T16:10:04.300885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, N, H, d_model, dk, dv, dff, \n",
    "                 vocab_size, max_positional_encoding, \n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        initializer = tf.keras.initializers.GlorotUniform()\n",
    "        self.embedding = tf.Variable(initializer(shape=(vocab_size, d_model)), trainable=True)\n",
    "        self.PE = positional_encoding(max_positional_encoding, d_model)\n",
    "        \n",
    "        self.dropout_encoding_input = Dropout(dropout_rate)\n",
    "        self.dropout_decoding_input = Dropout(dropout_rate)\n",
    "        \n",
    "        self.encoder = Encoder(N, H, d_model, dk, dv, dff, dropout_rate=dropout_rate, layernorm_eps=layernorm_eps)\n",
    "        self.decoder = Decoder(N, H, d_model, dk, dv, dff, dropout_rate=dropout_rate, layernorm_eps=layernorm_eps)\n",
    "\n",
    "        \n",
    "\n",
    "    def call(self, x, y, training=False, enc_padding_mask=None, look_ahead_mask=None, dec_padding_mask=None):\n",
    "        \n",
    "        x = tf.matmul(x,self.embedding)\n",
    "        x = x + self.PE\n",
    "        x =  self.dropout_encoding_input(x,training=training)\n",
    "        \n",
    "        encoder_output = self.encoder(x,training=training, mask=enc_padding_mask)\n",
    "        \n",
    "        y = tf.matmul(y,self.embedding)\n",
    "        y = y + self.PE\n",
    "        y = self.dropout_decoding_input(y,training=training)\n",
    "        \n",
    "        dec_output = self.decoder(y, encoder_output, training=training, \n",
    "                                  look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask)\n",
    "        \n",
    "        \n",
    "        pred =  tf.matmul(self.embedding,dec_output,transpose_b=True)\n",
    "        pred = tf.nn.softmax(pred)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "734af379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:04.390060Z",
     "iopub.status.busy": "2025-01-31T16:10:04.389613Z",
     "iopub.status.idle": "2025-01-31T16:10:04.737242Z",
     "shell.execute_reply": "2025-01-31T16:10:04.736737Z"
    },
    "papermill": {
     "duration": 0.376833,
     "end_time": "2025-01-31T16:10:04.737385",
     "exception": false,
     "start_time": "2025-01-31T16:10:04.360552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 29, 11)\n",
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_35 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "encoder_1 (Encoder)          multiple                  18902016  \n",
      "_________________________________________________________________\n",
      "decoder_1 (Decoder)          multiple                  25199616  \n",
      "=================================================================\n",
      "Total params: 44,116,480\n",
      "Trainable params: 44,116,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N, H, d_model, dk, dv, dff = 6, 8, 512, 64, 64, 2048\n",
    "vocab_size, T =29, 11\n",
    "batch_size = 3\n",
    "\n",
    "\n",
    "transformer = Transformer(N, H, d_model, dk, dv, dff, \n",
    "                 vocab_size, T)\n",
    "\n",
    "input_shape = (None, T,vocab_size)\n",
    "\n",
    "\n",
    "x = tf.random.uniform((batch_size, T, vocab_size))\n",
    "y =  tf.random.uniform((batch_size, T, vocab_size))\n",
    "\n",
    "pred = transformer(x,y,training=True)\n",
    "print(pred.shape)\n",
    "\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c2e41",
   "metadata": {
    "papermill": {
     "duration": 0.0242,
     "end_time": "2025-01-31T16:10:04.786591",
     "exception": false,
     "start_time": "2025-01-31T16:10:04.762391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d634c4e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:04.840126Z",
     "iopub.status.busy": "2025-01-31T16:10:04.839677Z",
     "iopub.status.idle": "2025-01-31T16:10:04.842309Z",
     "shell.execute_reply": "2025-01-31T16:10:04.841872Z"
    },
    "papermill": {
     "duration": 0.031173,
     "end_time": "2025-01-31T16:10:04.842412",
     "exception": false,
     "start_time": "2025-01-31T16:10:04.811239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We implement a callback that should be called during training to update the learning rate\n",
    "\n",
    "warmup_step = 4000\n",
    "class LearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_start(self, i, batch_logs):\n",
    "        transformer.optimizer.lr = dk**(-0.5)*min(i**(-0.5),warmup_step**(-3/2)*i)\n",
    "\n",
    "\n",
    "callback = LearningRateScheduler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a171d7",
   "metadata": {
    "papermill": {
     "duration": 0.024365,
     "end_time": "2025-01-31T16:10:04.891162",
     "exception": false,
     "start_time": "2025-01-31T16:10:04.866797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compilation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f986cf36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T16:10:04.949768Z",
     "iopub.status.busy": "2025-01-31T16:10:04.948999Z",
     "iopub.status.idle": "2025-01-31T16:10:04.955042Z",
     "shell.execute_reply": "2025-01-31T16:10:04.954692Z"
    },
    "papermill": {
     "duration": 0.036852,
     "end_time": "2025-01-31T16:10:04.955137",
     "exception": false,
     "start_time": "2025-01-31T16:10:04.918285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0, beta_1=0.9, beta_2=0.98, epsilon=1e-09)\n",
    "\n",
    "transformer.compile(loss='crossentropy',optimizer=optimizer,metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30157,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.438991,
   "end_time": "2025-01-31T16:10:08.685965",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-31T16:09:42.246974",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
