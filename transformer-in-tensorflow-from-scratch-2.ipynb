{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "831a73ee",
   "metadata": {
    "papermill": {
     "duration": 0.003621,
     "end_time": "2025-02-08T15:56:49.842295",
     "exception": false,
     "start_time": "2025-02-08T15:56:49.838674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Implementation of the transformer architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7ea37",
   "metadata": {
    "papermill": {
     "duration": 0.001629,
     "end_time": "2025-02-08T15:56:49.846328",
     "exception": false,
     "start_time": "2025-02-08T15:56:49.844699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7075d379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T15:56:49.851884Z",
     "iopub.status.busy": "2025-02-08T15:56:49.851404Z",
     "iopub.status.idle": "2025-02-08T15:57:06.192795Z",
     "shell.execute_reply": "2025-02-08T15:57:06.191349Z"
    },
    "papermill": {
     "duration": 16.346608,
     "end_time": "2025-02-08T15:57:06.194776",
     "exception": false,
     "start_time": "2025-02-08T15:56:49.848168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, Input, Dropout, LayerNormalization, Conv1D, Reshape\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe0d23",
   "metadata": {
    "papermill": {
     "duration": 0.001897,
     "end_time": "2025-02-08T15:57:06.199093",
     "exception": false,
     "start_time": "2025-02-08T15:57:06.197196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sub layers\n",
    "\n",
    "**Attention m - Single head attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a534c6a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T15:57:06.205659Z",
     "iopub.status.busy": "2025-02-08T15:57:06.205048Z",
     "iopub.status.idle": "2025-02-08T15:57:06.211798Z",
     "shell.execute_reply": "2025-02-08T15:57:06.210592Z"
    },
    "papermill": {
     "duration": 0.011944,
     "end_time": "2025-02-08T15:57:06.213754",
     "exception": false,
     "start_time": "2025-02-08T15:57:06.201810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V, mask = None):\n",
    "    \"\"\" \n",
    "    Calculate the attention weights\n",
    "\n",
    "    Arguments:\n",
    "    Q -- query shape ==(... Tq, dk)\n",
    "    K -- key shape == (..., Tv, dk)\n",
    "    V -- value shape == (.., Tb, dv)\n",
    "    mask: float tensor with shape broadcastable to (..., Tq, Tv). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        output -- (attention,attention_weights)\n",
    "    \"\"\"\n",
    "    #Compute the scaled dot-product Q*K\n",
    "    matmul_QK = tf.matmul(Q, K, transpose_b = True) # dot-product of shape (..., tq, Tv)\n",
    "\n",
    "    dk = K.shape[-1]\n",
    "    scaled_attention_logits = matmul_QK/np.sqrt(dk) # scaled dot_product of shape (..., Tq, Tv)\n",
    "\n",
    "    # add the mask to the scaled dot-product\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (1. - mask)*(-1e9)\n",
    "\n",
    "    #compute the Softmax\n",
    "    attention_weights = tf.nn.softmax(scaled_attntion_logits, axis = -1) # weights of shape (.., Tq, Tv)\n",
    "\n",
    "    #Multiply with V\n",
    "    output - tf.matmul(attention_weights, V) #Attention representation of shape (...., Tq, dv)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ea8d3",
   "metadata": {
    "papermill": {
     "duration": 0.001846,
     "end_time": "2025-02-08T15:57:06.217940",
     "exception": false,
     "start_time": "2025-02-08T15:57:06.216094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.602157,
   "end_time": "2025-02-08T15:57:08.619480",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-08T15:56:47.017323",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
