{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3f4c93",
   "metadata": {
    "papermill": {
     "duration": 0.003128,
     "end_time": "2025-02-12T08:54:26.163391",
     "exception": false,
     "start_time": "2025-02-12T08:54:26.160263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Implementation of the transformer architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98197bb",
   "metadata": {
    "papermill": {
     "duration": 0.002285,
     "end_time": "2025-02-12T08:54:26.168582",
     "exception": false,
     "start_time": "2025-02-12T08:54:26.166297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9bd3298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T08:54:26.175232Z",
     "iopub.status.busy": "2025-02-12T08:54:26.174743Z",
     "iopub.status.idle": "2025-02-12T08:54:42.565586Z",
     "shell.execute_reply": "2025-02-12T08:54:42.564214Z"
    },
    "papermill": {
     "duration": 16.39614,
     "end_time": "2025-02-12T08:54:42.567352",
     "exception": false,
     "start_time": "2025-02-12T08:54:26.171212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, Input, Dropout, LayerNormalization, Conv1D, Reshape\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a83d64",
   "metadata": {
    "papermill": {
     "duration": 0.002391,
     "end_time": "2025-02-12T08:54:42.572537",
     "exception": false,
     "start_time": "2025-02-12T08:54:42.570146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sub layers\n",
    "\n",
    "**Attention m - Single head attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c350f19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T08:54:42.579264Z",
     "iopub.status.busy": "2025-02-12T08:54:42.578572Z",
     "iopub.status.idle": "2025-02-12T08:54:42.584892Z",
     "shell.execute_reply": "2025-02-12T08:54:42.583951Z"
    },
    "papermill": {
     "duration": 0.011616,
     "end_time": "2025-02-12T08:54:42.586689",
     "exception": false,
     "start_time": "2025-02-12T08:54:42.575073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "\n",
    "    Arguments:\n",
    "        Q -- query shape == (..., Tq, dk)\n",
    "        K -- key shape == (..., Tv, dk)\n",
    "        V -- value shape == (..., Tv, dv)\n",
    "        mask: Float tensor with shape broadcastable to (..., Tq, Tv). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        output -- (attention,attention_weights)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Compute the scaled dot-product Qâ€¢K\n",
    "    matmul_QK = tf.matmul(Q,K,transpose_b=True)  # dot-product of shape (..., Tq, Tv)\n",
    "\n",
    "    dk = K.shape[-1]\n",
    "    scaled_attention_logits = matmul_QK/np.sqrt(dk) # scaled dot-product of shape (..., Tq, Tv)\n",
    "\n",
    "    # Add the mask to the scaled dot-product\n",
    "    if mask is not None: \n",
    "        scaled_attention_logits += (1. - mask) *(-1e9)\n",
    "\n",
    "    # Compute the Softmax\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # weights of shape (..., Tq, Tv)\n",
    "\n",
    "    #Multiply with V\n",
    "    output = tf.matmul(attention_weights,V)  # Attention representation of shape (..., Tq, dv)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ead57e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T08:54:42.593425Z",
     "iopub.status.busy": "2025-02-12T08:54:42.593083Z",
     "iopub.status.idle": "2025-02-12T08:54:42.652543Z",
     "shell.execute_reply": "2025-02-12T08:54:42.651354Z"
    },
    "papermill": {
     "duration": 0.065004,
     "end_time": "2025-02-12T08:54:42.654496",
     "exception": false,
     "start_time": "2025-02-12T08:54:42.589492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 9, 128)\n"
     ]
    }
   ],
   "source": [
    "batch_size, Tq, Tv, dk, dv = 16, 9,9, 64, 128\n",
    "Q = tf.random.uniform((batch_size, Tq, dk))\n",
    "K = tf.random.uniform((batch_size, Tv, dk))\n",
    "V = tf.random.uniform((batch_size, Tv, dv))\n",
    "\n",
    "A,_= scaled_dot_product_attention(Q, K, V)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b9262",
   "metadata": {
    "papermill": {
     "duration": 0.002443,
     "end_time": "2025-02-12T08:54:42.659805",
     "exception": false,
     "start_time": "2025-02-12T08:54:42.657362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### MultiHead Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a933e136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T08:54:42.666546Z",
     "iopub.status.busy": "2025-02-12T08:54:42.666169Z",
     "iopub.status.idle": "2025-02-12T08:54:42.674969Z",
     "shell.execute_reply": "2025-02-12T08:54:42.673802Z"
    },
    "papermill": {
     "duration": 0.01451,
     "end_time": "2025-02-12T08:54:42.677031",
     "exception": false,
     "start_time": "2025-02-12T08:54:42.662521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Multihead_Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, H, d_model, dk, dv):\n",
    "        \n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        H -- number of heads (=8 in the paper)\n",
    "        d_models -- embedding dimension (=512 in the paper)\n",
    "        dk -- depth of Q and K (=64 in the paper)\n",
    "        dv -- depth of V (=64 in the paper)\n",
    "        \"\"\"\n",
    "    \n",
    "        super(Multihead_Attention, self).__init__()\n",
    "        \n",
    "        initializer = tf.keras.initializers.GlorotUniform()\n",
    "        self.WQ = tf.Variable(initializer(shape=(H, d_model, dk)), trainable=True)\n",
    "        self.WK = tf.Variable(initializer(shape=(H, d_model, dk)), trainable=True)\n",
    "        self.WV = tf.Variable(initializer(shape=(H, d_model, dv)), trainable=True)\n",
    "        self.WO = tf.Variable(initializer(shape=(H*dv,d_model)), trainable=True)\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask=None):\n",
    "        \"\"\"\n",
    "        Calculate the attention weights.\n",
    "\n",
    "        Arguments:\n",
    "            Q -- query shape == (..., Tq, d_model)\n",
    "            K -- key shape == (..., Tv, d_model)\n",
    "            V -- value shape == (..., Tv, d_model)\n",
    "            mask: Float tensor with shape broadcastable to (..., Tq, Tv). Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            output -- Multihead attention A of shape (batch_size, Tq, d_model)\n",
    "        \"\"\"\n",
    "        #Projecting Q,K,V to Qh, Kh, Vh. The H projection are stacked on the penultiem axis\n",
    "        Qh= tf.experimental.numpy.dot(Q, self.WQ) #of shape (batch_size, Tq, H, dk)\n",
    "        Kh= tf.experimental.numpy.dot(K, self.WK) #of shape (batch_size, Tv, H, dk)\n",
    "        Vh= tf.experimental.numpy.dot(V, self.WV) #of shape (batch_size, Tv, H, dv)\n",
    "        \n",
    "        #Transposition\n",
    "        Qh=tf.transpose(Qh, [0,2,1,3]) #of shape (batch_size, H, Tq, dk)\n",
    "        Kh=tf.transpose(Kh, [0,2,1,3]) #of shape (batch_size, H, Tv, dk)\n",
    "        Vh=tf.transpose(Vh, [0,2,1,3]) #of shape (batch_size, H, Tv, dv)\n",
    "        \n",
    "        # Computing the dot-product attention\n",
    "        Ah,_=scaled_dot_product_attention(Qh, Kh, Vh, mask=mask) #of shape (batch_size, H, Tq, dv)\n",
    "        \n",
    "        #Flattening the H and dv axis and projecting back to d_model\n",
    "#        A = tf.reshape(Ah,(*Ah.shape[:-2],-1))\n",
    "        s=Ah.shape\n",
    "        A = tf.reshape(Ah,(s[0],s[2],s[1]*s[3])) #of shape (batch_size, Tq, H*dv)\n",
    "        A= tf.experimental.numpy.dot(A, self.WO) #of shape (batch_size, Tq, d_model)\n",
    "        \n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddaf2de",
   "metadata": {
    "papermill": {
     "duration": 0.002411,
     "end_time": "2025-02-12T08:54:42.682338",
     "exception": false,
     "start_time": "2025-02-12T08:54:42.679927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.899815,
   "end_time": "2025-02-12T08:54:44.208314",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-12T08:54:23.308499",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
